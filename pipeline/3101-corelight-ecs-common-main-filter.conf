# Corelight ECS Logstash Pipeline
# Git Repository: https://github.com/corelight/ecs-logstash-mappings
# Authors: Corelight Inc, Brasi Tech LLC
# License: BSD 3-Clause
# Support: https://github.com/corelight/ecs-logstash-mappings/issues/new
# Releases: https://github.com/corelight/ecs-logstash-mappings/releases

# General pipeline for configurations common amongst all Corelight/Zeek data/log types
filter {
  if [@metadata][z_no_reuse][event_type] == "corelight" {

    mutate {
      add_field => {
        "[@metadata][temporary_metadata_is_protocol_log]" => "yes"
        "[ecs][version]" => "8.11.0"
        "[labels][corelight][ecs_version]" => "8.11.0.1"
        "[labels][corelight][ecs_method]" => "logstash_pipeline"
        "[labels][corelight][ecs_method_version]" => "2023120101"
        "[event][kind]" => "tbd"
        "[event][category]" => "tbd"
        "[event][type]" => "tbd"
        "[event][module]" => "corelight"
        "[labels][corelight][event_category]" => "tbd"
        "[labels][corelight][event_sub_type]" => "tbd"
        "[observer][type]" => "sensor"
        "[observer][vendor]" => "Corelight"
        "[@metadata][etl][pipeline]" => "filter-mutate-9b1fb80a7bc6-2023120101"
      }
      tag_on_failure => "_mutate_error-9b1fb80a7bc6-2023120101"
      id => "filter-mutate-9b1fb80a7bc6"
    }
    
    # Set log type (event.dataset)
    if [_path] {
      mutate {
        rename => { "_path" => "[event][dataset]" }
        copy => { "[event][dataset]" => "[labels][corelight][event_sub_type]" }
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-99b7c5e52fc9-2023120101"
        }
        tag_on_failure => "_mutate_error-99b7c5e52fc9"
        id => "filter-mutate-99b7c5e52fc9"  
      }
    }
    else if [@stream] {
      mutate {
        rename => { "@stream" => "[event][dataset]" }
        copy => { "[event][dataset]" => "[labels][corelight][event_sub_type]" }
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-56d4d8a0c2b8-2023120101"
        }
        tag_on_failure => "_mutate_error-56d4d8a0c2b8-2023120101"
        id => "filter-mutate-56d4d8a0c2b8"  
      }
    }
    else if [@path] {
      mutate {
        rename => { "@path" => "[event][dataset]" }
        copy => { "[event][dataset]" => "[labels][corelight][event_sub_type]" }
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-c6bf25cf2570-2023120101"
        }
        tag_on_failure => "_mutate_error-c6bf25cf2570-2023120101"
        id => "filter-mutate-c6bf25cf2570"  
      }
    }
    # SecurityOnion specific 
    else if [dataset] {
      mutate {
        rename => { "dataset" => "[event][dataset]" }
        copy => { "[event][dataset]" => "[labels][corelight][event_sub_type]" }
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-00e12205708a-2023120101"
        }
        tag_on_failure => "_mutate_error-00e12205708a-2023120101"
        id => "filter-mutate-20220405"  
      }
    }
    else if [type] {
      mutate {
        rename => { "type" => "[event][dataset]" }
        copy => { "[event][dataset]" => "[labels][corelight][event_sub_type]" }
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-b5f2b963dc1d-2023120101"
        }
        tag_on_failure => "_mutate_error-b5f2b963dc1d-2023120101"
        id => "filter-mutate-b5f2b963dc1d"  
      }
    }
    # Unknown log type...
    else {
      mutate {
        add_field => {
          "[@metadata][etl][info_tags]" => "missing field denoting log file. should be one of @path,_path,@stream,type,etc."
          "[@metadata][etl][pipeline]" => "filter-mutate-d6bf25cf2570-2023120101"
        }
        tag_on_failure => "_mutate_error-d6bf25cf2570-2023120101"
        id => "filter-mutate-d6bf25cf2570" 
      }
    }

    # If any log name contains \"^bro_\" (for older versions) then remove that from event.dataset to keep them from being decoupled
    if [event][dataset] and [event][dataset] =~ "^bro_" {
      mutate {
        gsub => [
          "[event][dataset]", "^bro_", "",
          "[labels][corelight][event_sub_type]", "^bro_", ""
        ]
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-b9790d65d013-2024010901"
        }
        tag_on_failure => "_mutate_error-b9790d65d013-2024010901"
        id => "filter-mutate-b9790d65d013"
      }
    }

    # parse ts field to @timestamp. treat files_red.log different than any other log as it has an array of 1 or more values and use the first value for @timestamp
    if [ts] {

      if [event][dataset] == "files_red" {
        ruby {
          code => '
            ts_original = event.get("ts")
            event.set("files_red_ts_original", ts_original)
            if ts_original.is_a? Enumerable
              ts_timestamp = ts_original.first
              event.set("ts", ts_timestamp)
            end
          '
          tag_on_exception => "_rubyexception-933b410e331f-files_red-ts_timestamp"
          tag_with_exception_message => true
          add_field => {
            "[@metadata][etl][pipeline]" => "filter-ruby-933b410e331f-2023120101"
          }
          id => "filter-ruby-933b410e331f"
        }
        date {
          match => [ "ts", "ISO8601", "UNIX" ]
          #timezone => "UTC"
          target => "@timestamp"
          remove_field => "ts"
          add_field => {
            "[@metadata][etl][pipeline]" => "filter-date-32d9ccd700b7-2023120101"
          }
          tag_on_failure => [ "_dateparsefailure", "_dateparsefailure-32d9ccd700b7-2023120101", "_parsefailure", "parse_failure_critical" ]
          id => "filter-date-32d9ccd700b7" 
        }

      }
      else {
        date {
          match => [ "ts", "ISO8601", "UNIX" ]
          #timezone => "UTC"
          target => "@timestamp"
          remove_field => "ts"
          add_field => {
            "[@metadata][etl][pipeline]" => "filter-date-83ccd8287a03-2023120101"
          }
          tag_on_failure => [ "_dateparsefailure", "_dateparsefailure-83ccd8287a03-2023120101", "_parsefailure", "parse_failure_critical" ]
          id => "filter-date-83ccd8287a03" 
        }
      }
    }
    else if [start_time] {
      date {
        match => [ "start_time", "ISO8601", "UNIX" ]
        #timezone => "UTC"
        target => "@timestamp"
        remove_field => "start_time"
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-date-616a30bbbc74-2023120101"
        }
        tag_on_failure => [ "_dateparsefailure", "_dateparsefailure-616a30bbbc74-2023120101", "_parsefailure", "parse_failure_critical" ]
        id => "filter-date-616a30bbbc74" 
      }
    }
    else if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601", "UNIX" ]
        #timezone => "UTC"
        target => "@timestamp"
        remove_field => "timestamp"
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-date-e468e51bea52-2023120101"
        }
        tag_on_failure => [ "_dateparsefailure", "_dateparsefailure-e468e51bea52-2023120101", "_parsefailure", "parse_failure_critical" ]
        id => "filter-date-e468e51bea52" 
      }
    }
    # Unknown timestamp...
    else {
      mutate {
        add_field => {
          "[@metadata][etl][info_tags]" => "missing field denoting original timestamp. should be one of ts, start_time,etc."
          "[@metadata][etl][pipeline]" => "filter-mutate-a6e8efd0c923-2023120101"
        }
        tag_on_failure => "_mutate_error-a6e8efd0c923-2023120101"
        id => "filter-mutate-a6e8efd0c923" 
      }
    }
    
    # _write_ts
    if [_write_ts] {
      date {
        match => [ "_write_ts", "ISO8601" ]
        #timezone => "UTC"
        target => "[event][created]"
        remove_field => "_write_ts"
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-date-52af0995fbed-2023120101"
        }
        tag_on_failure => [ "_dateparsefailure", "_dateparsefailure-52af0995fbed-2023120101", "_parsefailure", "parse_failure_critical" ]
        id => "filter-date-52af0995fbed" 
      }
    }
    
    # Set host name (observer.hostname)
    if [_system_name] {
      mutate {
        rename => {
          "_system_name" => "[observer][hostname]"
        }
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-89ed0e29d828-2023120101"
        }
        tag_on_failure => "_mutate_error-89ed0e29d828-2023120101"
        id => "filter-mutate-89ed0e29d828"
      }
    }
    else if [@sensor] {
      mutate {
        rename => {
          "@sensor" => "[observer][hostname]"
        }
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-efe993820f67-2023120101"
        }
        tag_on_failure => "_mutate_error-efe993820f67-2023120101"
        id => "filter-mutate-efe993820f67"
      }
    }
    else if [@system] {
      mutate {
        rename => {
          "@system" => "[observer][hostname]"
        }
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-be415e6e6542-2023120101"
        }
        tag_on_failure => "_mutate_error-be415e6e6542-2023120101"
        id => "filter-mutate-be415e6e6542"
      }
    }

    # Rename any potential collisions of ECS schema with regular fields
    mutate {
      rename => {
        "host" => "temp_host"
        "port" => "temp_port"
        "source" => "temp_source"
      }
    }
    
    # Make common name for variations of ports and IP fields.
    # such as, id.orig_h VS id_orig_h
    # underscore notated id fields
    if [id_orig_h] or [id_resp_h] or [id_orig_p] or [id_resp_p] or [id_vlan] {
      mutate {
        rename => {
          "id_orig_h" => "[source][ip]"
          "id_orig_p" => "[source][port]"
          "id_resp_h" => "[destination][ip]"
          "id_resp_p" => "[destination][port]"
          "id_vlan" => "temp_vlan"
        }
        add_field => {
          "[@metadata][pipeline_internal][corelight_dotted_fields]" => "false"
          "[@metadata][etl][pipeline]" => "filter-mutate-55baf582cf19-2024010901"
        }
        tag_on_failure => "_mutate_error-55baf582cf19-2024010901"
        id => "filter-mutate-55baf582cf19"
      }
    }
    # nested dot notated id fields
    else if [id][orig_h] or [id][orig_p] or [id][resp_h] or [id][resp_p] or [id][vlan] {
      mutate {
        rename => {
          "[id][orig_h]" => "[source][ip]"
          "[id][orig_p]" => "[source][port]"
          "[id][resp_h]" => "[destination][ip]"
          "[id][resp_p]" => "[destination][port]"
          "[id][vlan]" => "temp_vlan"
        }
        #copy => {
        #  "[source][ip]" => "[source][address]"
        #  "[destination][ip]" => "[destination][address]"
        #}
        add_field => {
          "[@metadata][pipeline_internal][corelight_dotted_fields]" => "true"
          "[@metadata][etl][pipeline]" => "filter-mutate-f8178808e7ea-2024010901"
        }
        tag_on_failure => "_mutate_error-f8178808e7ea-2024010901"
        id => "filter-mutate-f8178808e7ea"
      }
      # Check if id is empty object/dictionary
      if [id] {
        ruby {
          code => '
            if event.get("id").is_a?(Hash) && event.get("id").empty?
              event.remove("id")
            end
          '
          tag_on_exception => "_rubyexception-69e7108421d6"
          tag_with_exception_message => true
          add_field => {
            "[@metadata][etl][pipeline]" => "filter-ruby-69e7108421d6-2024010901"
          }
          id => "filter-ruby-69e7108421d6"
        }
      }
    }
    # dot notated id fields
    else {
      mutate {
        rename => {
          "id.orig_h" => "[source][ip]"
          "id.orig_p" => "[source][port]"
          "id.resp_h" => "[destination][ip]"
          "id.resp_p" => "[destination][port]"
          "id.vlan" => "temp_vlan"
        }
        #copy => {
        #  "[source][ip]" => "[source][address]"
        #  "[destination][ip]" => "[destination][address]"
        #}
        add_field => {
          "[@metadata][pipeline_internal][corelight_dotted_fields]" => "true"
          "[@metadata][etl][pipeline]" => "filter-mutate-178d76e8a887-2023120101"
        }
        tag_on_failure => "_mutate_error-178d76e8a887-2023120101"
        id => "filter-mutate-178d76e8a887"
      }
    }    
    
    # Common renames 
    mutate {
      rename => {
        "cert_chain_fuids" => "[log][id][cert_chain_fuids]"
        "client_cert_chain_fuids" => "[log][id][client_cert_chain_fuids]"
        "client_cert_fuid" => "[log][id][client_cert_fuid]"
        "community_id" => "[network][community_id]"
        "conn_uids" => "[log][id][conn_uids]"
        "fid" => "[log][id][fid]"
        "flow_id" => "[log][id][flow_id]"
        "fuid" => "[log][id][fuid]"
        "fuids" => "[log][id][fuids]"
        "id" => "[log][id][id]"
        "inner_vlan" => "[network][inner][vlan][id]"
        "orig_fuids" => "[log][id][orig_fuids]"
        "outer_vlan" => "[network][vlan][id]"
        "parent_fuid" => "[log][id][parent_fuid]"
        "proto" => "[network][transport]"
        "related_fuids" => "[log][id][related_fuids]"
        "resp_fuids" => "[log][id][resp_fuids]"
        "server_cert_fuid" => "[log][id][server_cert_fuid]"
        "suri_id" => "[log][id][suri_id]"
        "suri_ids" => "[log][id][suri_ids]"
        "tx_id" => "[log][id][tx_id]"
        "uid" => "[log][id][uid]"
        "uids" => "[log][id][uids]"
        "user_agent" => "[user_agent][original]"
        "uuid" => "[log][id][uuid]"
        "vlan" => "[network][vlan][id]"
        "vlan_inner" => "[network][inner][vlan][id]"
      }
      copy => {
        "[log][id][uid]" => "[event][id]"
      }
      add_field => {
        "[@metadata][etl][pipeline]" => "filter-mutate-0949382998a7-2023120101"
      }
      tag_on_failure => "_mutate_error-0949382998a7-2023120101"
      id => "filter-mutate-0949382998a7" 
    }

    # Remove potentially blank fields
    #ruby {
    #  code => '
    #    value_for_destination = event.get("destination")
    #    event.remove("destination") if value_for_destination.nil? || (value_for_destination.respond_to?(:empty?) && value_for_destination.empty?)
    #    value_for_network = event.get("network")
    #    event.remove("network") if value_for_network.nil? || (value_for_network.respond_to?(:empty?) && value_for_network.empty?)
    #    value_for_source = event.get("source")
    #    event.remove("source") if value_for_source.nil? || (value_for_source.respond_to?(:empty?) && value_for_source.empty?)
    #    value_for_tags = event.get("tags")
    #    event.remove("tags") if value_for_tags.nil? || (value_for_tags.respond_to?(:empty?) && value_for_tags.empty?)
    #    value_for_temp_vlan = event.get("temp_vlan")
    #    event.remove("temp_vlan") if value_for_temp_vlan.nil? || (value_for_temp_vlan.respond_to?(:empty?) && value_for_temp_vlan.empty?)
    #    value_for_user_agent = event.get("user_agent")
    #    event.remove("user_agent") if value_for_user_agent.nil? || (value_for_user_agent.respond_to?(:empty?) && value_for_user_agent.empty?)
    #  '
    #  add_field => {
    #    "[@metadata][etl][pipeline]" => "filter-ruby-97dedd136804-2023120101"
    #  }
    #  tag_on_exception => "_rubyexception-97dedd136804-remove_blank_fields-2023120101"
    #  tag_with_exception_message => true
    #  id => "filter-ruby-97dedd136804"
    #}       
    #
    # Set VLAN and possibilities of existing and not existing and preventing duplicates if existing already
    if [temp_vlan] {
      if [network][vlan][id] {
        if [temp_vlan] == [network][vlan][id] {
          mutate {
            remove_field => [ "temp_vlan" ]
            add_field => {
              "[@metadata][etl][pipeline]" => "filter-mutate-1ed553cea220-2023120101"
            }
            tag_on_failure => "_mutate_error-1ed553cea220-2023120101"
            id => "filter-mutate-1ed553cea220"
          }
        } 
      }
      else {
        mutate {
          rename => { "temp_vlan" => "[network][vlan][id]" }
          add_field => {
            "[@metadata][etl][pipeline]" => "filter-mutate-fe054b13bfe6-2023120101"
          }
          tag_on_failure => "_mutate_error-fe054b13bfe6-2023120101"
          id => "filter-mutate-fe054b13bfe6"
        }
      }
    }

    # If any log name contains "_red$" (for reduced) then remove that from event.dataset to keep them from being decoupled even though it has identical field names, for the fields it does have, (ie: should go through the same config process) as it's counterpart. ie: dns_red can be treated indentically as dns.
    if [event][dataset] {
      mutate {
        gsub => ["[event][dataset]", "_red$", "" ]
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-6ccfdddc8e9b-2023120101"
        }
        tag_on_failure => "_mutate_error-6ccfdddc8e9b-2023120101"
        id => "filter-mutate-6ccfdddc8e9b"
      }
    }

    # If any log name contains "^bro_" (for older versions) then remove that from event.dataset to keep them from being decoupled
    if [event][dataset] {
      mutate {
        gsub => ["[event][dataset]", "^bro_", "" ]
        add_field => {
          "[@metadata][etl][pipeline]" => "filter-mutate-66c4ca61814c-2023120101"
        }
        tag_on_failure => "_mutate_error-66c4ca61814c-2023120101"
        id => "filter-mutate-66c4ca61814c"
      }
    }

  }
}
